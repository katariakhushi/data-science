{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "### making request\n",
    "response=requests.get('https://medium.com/codingninjas-blog')\n",
    "\n",
    "### parsing data\n",
    "data=BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "### fetching first 5 blogs\n",
    "allBlogs=data.find_all('h3')\n",
    "count=0\n",
    "for title in allBlogs:\n",
    "    if count==5:\n",
    "        break\n",
    "    print(title.string)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "response = requests.get('http://books.toscrape.com/')\n",
    "html_data = response.text\n",
    "data = BeautifulSoup(html_data, 'html.parser')\n",
    "cat = data.find(class_='side_categories')\n",
    "c=cat.find_all('a')\n",
    "for i in c:\n",
    "    if i.string.strip() != \"Books\":\n",
    "        print(i.string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_urls = ['http://quotes.toscrape.com/page/1/']\n",
    "base = 'http://quotes.toscrape.com'\n",
    "\n",
    "response = requests.get(all_urls[0])\n",
    "\n",
    "while response.status_code == 200 :\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    if data.find(class_ = 'next') is None : \n",
    "        break\n",
    "        \n",
    "    url = data.find(class_ = 'next').a['href']\n",
    "    all_urls.append(base+url)  \n",
    "    response = requests.get(all_urls[-1])\n",
    "    \n",
    "for i in all_urls :\n",
    "    response = requests.get(i)\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for j in data.find_all(class_ = 'quote'):\n",
    "        s = j.find(class_ = 'author').string\n",
    "        if s == 'Albert Einstein' :\n",
    "            s= j.find(class_ = 'text').string\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_urls = ['http://quotes.toscrape.com/page/1/']\n",
    "base = 'http://quotes.toscrape.com'\n",
    "\n",
    "response = requests.get(all_urls[0])\n",
    "\n",
    "while response.status_code == 200 :\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "    if data.find(class_ = 'next') is None : \n",
    "        break\n",
    "        \n",
    "    url = data.find(class_ = 'next').a['href']\n",
    "    all_urls.append(base+url)  \n",
    "    response = requests.get(all_urls[-1])\n",
    "    \n",
    "auth_name = []\n",
    "for i in all_urls :\n",
    "    response = requests.get(i)\n",
    "    data = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for j in data.find_all(class_ = 'quote'):\n",
    "        name = j.find(class_ = 'author').string\n",
    "        if name not in auth_name:\n",
    "            auth_name.append(name)\n",
    "            \n",
    "for name in sorted(auth_name):\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
